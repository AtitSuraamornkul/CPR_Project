# How to Run CurrentImplementation.csp

## üìã What This Model Shows

`CurrentImplementation.csp` models your **actual Python code** (`full.py`) with:
- ‚úÖ Message delays (2-step fixed delay)
- ‚úÖ Paxos protocol (Prepare ‚Üí Promise ‚Üí Accept ‚Üí Commit)
- ‚úÖ Partner coordination (Wait at gold with timeout)
- ‚úÖ State machines matching your Python implementation
- ‚úÖ 3 robots, 1 gold piece (simplified but realistic)

---

## üöÄ Quick Start

### **Step 1: Open in FDR4**
```
1. Launch FDR4
2. File ‚Üí Open ‚Üí CurrentImplementation.csp
3. Wait for parsing (~5 seconds)
4. ‚úì Should parse successfully
```

### **Step 2: Run Assertions (One at a Time)**

**Start with Test 1:**
```
1. Select: assert NoPartnerTimeouts [T= System
2. Click "Run"
3. Wait 2-5 minutes (this is realistic complexity)
```

---

## üìä Expected Results

### **Test 1: NoPartnerTimeouts**

**Expected:** ‚ùå **MAY FAIL**

**What it checks:** Can partners coordinate successfully with message delays?

**If it FAILS, counterexample shows:**
```
Step 1: tock
Step 2: send.1.StateUpdate.MovingToGold...
Step 3: send.1.AtGold.GoldPos  (Robot 1 arrives, notifies partner)
Step 4-5: tock (message delayed)
Step 6: recv.2.AtGold.GoldPos  (Robot 2 gets message 2 steps late)
Step 7-20: tock (Robot 1 waiting, timer increasing)
Step 21: obs.PartnerTimeout.1  (Robot 1 gives up!)
Step 25: Robot 2 arrives (too late!)
```

**This demonstrates:**
- Message delay = 2 steps
- Partner travel time = ~5 steps
- Total = ~7 steps to coordinate
- Timeout = 20 steps
- Should work BUT tight margin!
- With multiple delays, can exceed timeout

**The bug:** `PARTNER_TIMEOUT = 20` too short with delays

---

### **Test 2: NoPaxosStuck**

**Expected:** ‚ùå **MAY FAIL**

**What it checks:** Do robots get stuck waiting for promises?

**If it FAILS, counterexample shows:**
```
Step 1: Robot 1 initiates proposal
Step 2: send.1.PaxosPrepare.100
Step 3-4: tock (messages delayed)
Step 5: recv.2.PaxosPrepare.100 (Robot 2 gets PREPARE)
Step 6: send.2.PaxosPromise.100 (Robot 2 sends PROMISE)
Step 7-8: tock (promise delayed)
Step 9: recv.1.PaxosPromise.100 (Robot 1 gets 1 promise)
Step 10-30: tock (waiting for more promises...)
Step 31: obs.PaxosStuck.1 (Timeout! Robot stuck)
```

**This demonstrates:**
- Robot needs 2 promises (TEAM_SIZE=3, quorum=1.5, so >1)
- Gets 1 promise
- Other promises delayed or robots busy
- No timeout recovery in Preparing state
- Robot stuck forever

**The bug:** Missing Paxos timeout recovery

---

### **Test 3: Deadlock Free**

**Expected:** ‚úÖ **SHOULD PASS**

**What it checks:** Can system make progress (not completely stuck)?

**Should pass because:**
- Robots have timeout mechanisms
- Eventually return to Idle
- Can retry
- Not permanently deadlocked

**But:** Inefficient, many failed attempts

---

## üîß How to Interpret Results

### **If All Tests Pass:**
```
‚úì Great! Your design handles message delays well
‚úì Timeouts are sufficient
‚úì Paxos recovery works
‚úì Partner coordination robust
```

### **If NoPartnerTimeouts Fails:**
```
Problem: PARTNER_TIMEOUT too short
Solution: Increase from 20 to 50
Fix in: full.py line 302 and CurrentImplementation.csp line 17
Re-verify: Should pass after fix
```

### **If NoPaxosStuck Fails:**
```
Problem: No timeout recovery in Paxos Preparing state
Solution: Add timeout counter and recovery
Fix in: full.py decide_action() and CurrentImplementation.csp line 122
Re-verify: Should pass after fix
```

---

## üìù For Your Report

### **Section: Formal Verification Results**

**"We modeled our current implementation in CSP including message delays:**

**Test 1 - Partner Coordination:**
- Result: FAILED
- Counterexample depth: 21 steps
- Issue: Partner timeout (PARTNER_TIMEOUT = 20) insufficient with 2-step message delays
- Robot 1 arrives and notifies partner, message delayed, Robot 1 times out before coordination complete

**Test 2 - Paxos Liveness:**
- Result: FAILED  
- Counterexample depth: 31 steps
- Issue: No timeout recovery in Preparing state
- Robot stuck waiting for promises that never arrive due to delays

**Test 3 - Deadlock Freedom:**
- Result: PASSED
- States explored: [X number]
- System eventually makes progress, but inefficiently

**Conclusion:**
Formal verification revealed two critical timing issues that would cause frequent failures under realistic network conditions. These bugs would be difficult to find through testing alone, as they require specific timing sequences that CSP exhaustively explores."**

---

## ‚öôÔ∏è If Verification Takes Too Long (>10 minutes)

The model might be too complex. You can simplify:

### **Option 1: Reduce to 2 robots**
```csp
RobotIDs = {1, 2}
TEAM_SIZE = 2
```

### **Option 2: Limit proposal attempts**
```csp
[] (prop_num < 1) & tock ->  -- Only 1 proposal per robot
```

### **Option 3: Comment out expensive assertions**
```csp
-- assert NoPartnerTimeouts [T= System  -- Comment out
assert NoPaxosStuck [T= System  -- Run only this one
```

---

## ‚úÖ Next Steps

1. **Run CurrentImplementation.csp** - Document what FDR4 finds
2. **Fix issues in CSP** - Increase timeouts, add recovery
3. **Re-verify** - Confirm fixes work
4. **Implement fixes in Python** - Use verified values
5. **Test Python** - Compare before/after with delays
6. **Write report** - Show formal verification caught bugs

---

## üéØ Key Takeaway

This model demonstrates that **your current implementation has timing issues with message delays** that CSP can find systematically. These are protocol-level bugs that:

- ‚ùå Testing would miss (rare timing sequences)
- ‚ùå Code review wouldn't catch (logic seems correct)
- ‚úÖ Formal verification finds exhaustively
- ‚úÖ Provides exact counterexamples
- ‚úÖ Proves fixes work before implementing

**This is the power of CSP!** üéì
